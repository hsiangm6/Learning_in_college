{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# from tensorflow.python.keras import models\n",
    "from keras import regularizers\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取訓練和測試資料\n",
    "train_label_csv = pd.read_csv(\"Arrhythmia Data Set-20230503T055529Z-001/Arrhythmia Data Set/train_label.csv\", header=None)\n",
    "train_data_csv = pd.read_csv(\"Arrhythmia Data Set-20230503T055529Z-001/Arrhythmia Data Set/train_data.csv\", header=None)\n",
    "test_label_csv = pd.read_csv(\"Arrhythmia Data Set-20230503T055529Z-001/Arrhythmia Data Set/test_label.csv\", header=None)\n",
    "test_data_csv = pd.read_csv(\"Arrhythmia Data Set-20230503T055529Z-001/Arrhythmia Data Set/test_data.csv\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 將資料和標籤分離\n",
    "# X_train = train_data.iloc[:, :].values.astype(np.float32)\n",
    "# y_train = train_label.iloc[:, -1].values\n",
    "# X_test = test_data.iloc[:, :].values.astype(np.float32)\n",
    "# y_test = test_label.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編碼標籤\n",
    "le = LabelEncoder().fit(train_label_csv[0]) #將類別標籤進行編碼，將文字或類別數值轉換成模型可以理解的數值型別。\n",
    "# y_train = le.fit_transform(y_train) #將訓練集的標籤進行編碼\n",
    "y_test = test_label_csv[0].map(lambda s:-1 if s not in le.classes_ else s)\n",
    "le.classes_=np.append(le.classes_, -1)\n",
    "y_train=le.transform(train_label_csv[0])\n",
    "y_test=le.transform(y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 199ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 49ms/step - loss: nan - val_loss: nan\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: nan - val_loss: nan\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: nan - val_loss: nan\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - val_loss: nan\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f07ff42fb0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用autoencoder進行降維處理\n",
    "input_dim = train_data_csv.shape[1]\n",
    "encoding_dim = 32\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "encoded = Dense(int(encoding_dim / 4), activation=\"tanh\")(encoder)\n",
    "decoder = Dense(int(encoding_dim / 2), activation=\"tanh\")(encoded)\n",
    "decoder = Dense(input_dim, activation=\"relu\")(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "autoencoder.fit(train_data_csv, train_data_csv,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_data_csv, test_data_csv),\n",
    "                verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用autoencoder進行降維處理\n",
    "encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "encoded_train = pd.DataFrame(encoder.predict(train_data_csv))\n",
    "encoded_test = pd.DataFrame(encoder.predict(test_data_csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - ETA: 0s - loss: nan - accuracy: 0.671 - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 19ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6621\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6621\n"
     ]
    }
   ],
   "source": [
    "#訓練分類器\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=int(encoding_dim/4)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(encoded_train, y_train, epochs=50, batch_size=128)\n",
    "\n",
    "# 預測標籤\n",
    "y_pred = model.predict(encoded_test).argmax(axis=1)\n",
    "num_classes = len(np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 5 0 1 1 1 0 0 0 1 0 4 1 7 0 0 0 0 2 0 0 5 0 0 4 0 0 0 0 0 0 0 0 0 0 2\n",
      " 0 0 0 0 4 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 2 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "unknown_indexes = np.where(y_test == -1)[0]\n",
    "unknown_x = test_data_csv.iloc[unknown_indexes]\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\hsian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1209\u001b[0m, in \u001b[0;36mDataHandler._truncate_execution_to_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[39mif\u001b[39;00m should_truncate:\n\u001b[1;32m-> 1209\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49massign(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps)\n\u001b[0;32m   1210\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'assign'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hsian\\Documents\\GitHub\\Learning_in_college\\Data_Mining\\期末專案\\pytorch_training.ipynb 儲存格 10\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hsian/Documents/GitHub/Learning_in_college/Data_Mining/%E6%9C%9F%E6%9C%AB%E5%B0%88%E6%A1%88/pytorch_training.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m unknown_indexes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y_test \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hsian/Documents/GitHub/Learning_in_college/Data_Mining/%E6%9C%9F%E6%9C%AB%E5%B0%88%E6%A1%88/pytorch_training.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m unknown_x \u001b[39m=\u001b[39m test_data_csv\u001b[39m.\u001b[39miloc[unknown_indexes]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hsian/Documents/GitHub/Learning_in_college/Data_Mining/%E6%9C%9F%E6%9C%AB%E5%B0%88%E6%A1%88/pytorch_training.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m unknown_x_encoded \u001b[39m=\u001b[39m encoder\u001b[39m.\u001b[39;49mpredict(unknown_x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hsian/Documents/GitHub/Learning_in_college/Data_Mining/%E6%9C%9F%E6%9C%AB%E5%B0%88%E6%A1%88/pytorch_training.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_train)), random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mfit(encoded_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hsian/Documents/GitHub/Learning_in_college/Data_Mining/%E6%9C%9F%E6%9C%AB%E5%B0%88%E6%A1%88/pytorch_training.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m unknown_labels \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mpredict(unknown_x_encoded)\n",
      "File \u001b[1;32mc:\\Users\\hsian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1737\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1735\u001b[0m callbacks\u001b[39m.\u001b[39mon_predict_begin()\n\u001b[0;32m   1736\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1737\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m   \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1739\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[1;32mc:\\Users\\hsian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1190\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39menumerate_epochs\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1189\u001b[0m   \u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1190\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m   1191\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset)\n\u001b[0;32m   1192\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n",
      "File \u001b[1;32mc:\\Users\\hsian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hsian\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1214\u001b[0m, in \u001b[0;36mDataHandler._truncate_execution_to_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1212\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1213\u001b[0m   \u001b[39mif\u001b[39;00m should_truncate:\n\u001b[1;32m-> 1214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49massign(original_value)\n\u001b[0;32m   1215\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_value \u001b[39m=\u001b[39m original_value\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "# 將未知類中的樣本進行分群並預測標籤\n",
    "unknown_indexes = np.where(y_test == -1)[0]\n",
    "unknown_x = test_data_csv.iloc[unknown_indexes]\n",
    "unknown_x_encoded = encoder.predict(unknown_x)\n",
    "kmeans = KMeans(n_clusters=len(np.unique(y_train)), random_state=0).fit(encoded_train)\n",
    "unknown_labels = kmeans.predict(unknown_x_encoded)\n",
    "\n",
    "# 將預測標籤與原始的分類器預測標籤合併\n",
    "predicted_labels = np.hstack([y_pred, unknown_labels + num_classes])\n",
    "\n",
    "# 將預測標籤轉換回原始的類別標籤\n",
    "predicted_labels = le.inverse_transform(predicted_labels)\n",
    "\n",
    "# 計算模型的準確率、召回率和F1分數\n",
    "print(classification_report(test_label_csv[0], predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將未知類中的樣本進行分群並預測標籤\n",
    "unknown_x = x_test[unknown_indexes]\n",
    "unknown_x_encoded = encoder.predict(unknown_x)\n",
    "unknown_labels = kmeans.predict(unknown_x_encoded)\n",
    "\n",
    "# 將預測標籤與原始的分類器預測標籤合併\n",
    "predicted_labels = np.hstack([y_pred, unknown_labels + num_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# 計算混淆矩陣和分類報告\n",
    "cm = confusion_matrix(y_test, predicted_labels)\n",
    "cr = classification_report(y_test, predicted_labels)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(cr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
